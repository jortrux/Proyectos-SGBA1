{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install tensorflow[and-cuda]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/david/proyectos4/repositorios/Proyectos-SGBA1/Pruebas/Modelos/precio_peninsula\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "dir_notebook = os.getcwd()\n",
    "print(dir_notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directorio de trabajo actual: /home/david/proyectos4/repositorios/Proyectos-SGBA1\n"
     ]
    }
   ],
   "source": [
    "ruta_trabajo = '../../../'\n",
    "\n",
    "# Cambiar el directorio de trabajo\n",
    "os.chdir(ruta_trabajo)\n",
    "\n",
    "print(\"Directorio de trabajo actual:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/david/proyectos4/repositorios/Proyectos-SGBA1\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargar df_clima_precio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_precio = pd.read_parquet('data/processed/datos_precio/clima_precio_merged.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install numpy pandas scikit-learn tensorflow xgboost lightgbm matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-22 20:39:56.612128: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1742672396.626973   37190 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1742672396.630828   37190 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1742672396.644129   37190 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1742672396.644150   37190 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1742672396.644152   37190 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1742672396.644153   37190 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-03-22 20:39:56.647207: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['€/kwh', 'fecha', 'indicativo_3196', 'altitud_3196', 'tmed_3196',\n",
       "       'tmin_3196', 'tmax_3196', 'velmedia_3196', 'racha_3196', 'sol_3196',\n",
       "       ...\n",
       "       'horaPresMax_cos_8175', 'horaPresMin_varias_8175',\n",
       "       'horaPresMin_minutos_8175', 'horaPresMin_sin_8175',\n",
       "       'horaPresMin_cos_8175', 'prec_inapreciable_8175', 'prec_valor_8175',\n",
       "       'prec_log_8175', 'dir_sin_8175', 'dir_cos_8175'],\n",
       "      dtype='object', length=479)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_precio.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-numeric columns: Index(['fecha', 'horaHrMax_3196', 'horaHrMin_3196', 'horaHrMax_9434',\n",
      "       'horaHrMin_9434', 'horaHrMax_9170', 'horaHrMin_9170', 'horaHrMax_2539',\n",
      "       'horaHrMin_2539', 'indicativo_6155A', 'horaHrMax_6155A',\n",
      "       'horaHrMin_6155A', 'horaHrMax_1505', 'horaHrMin_1505',\n",
      "       'indicativo_3469A', 'horaHrMax_3469A', 'horaHrMin_3469A',\n",
      "       'horaHrMax_8019', 'horaHrMin_8019', 'indicativo_0200E',\n",
      "       'horaHrMax_4121', 'horaHrMin_4121', 'horaHrMax_8175', 'horaHrMin_8175'],\n",
      "      dtype='object')\n",
      "       fecha horaHrMax_3196 horaHrMin_3196 horaHrMax_9434 horaHrMin_9434  \\\n",
      "0 2014-11-03         Varias         Varias         Varias         Varias   \n",
      "1 2014-11-03         Varias         Varias         Varias         Varias   \n",
      "2 2014-11-03         Varias         Varias         Varias         Varias   \n",
      "3 2014-11-03         Varias         Varias         Varias         Varias   \n",
      "4 2014-11-03         Varias         Varias         Varias         Varias   \n",
      "\n",
      "  horaHrMax_9170 horaHrMin_9170 horaHrMax_2539 horaHrMin_2539  \\\n",
      "0         Varias          18:23         Varias          12:00   \n",
      "1         Varias          18:23         Varias          12:00   \n",
      "2         Varias          18:23         Varias          12:00   \n",
      "3         Varias          18:23         Varias          12:00   \n",
      "4         Varias          18:23         Varias          12:00   \n",
      "\n",
      "  indicativo_6155A  ... indicativo_3469A horaHrMax_3469A horaHrMin_3469A  \\\n",
      "0            6155A  ...            3469A           08:00           11:40   \n",
      "1            6155A  ...            3469A           08:00           11:40   \n",
      "2            6155A  ...            3469A           08:00           11:40   \n",
      "3            6155A  ...            3469A           08:00           11:40   \n",
      "4            6155A  ...            3469A           08:00           11:40   \n",
      "\n",
      "  horaHrMax_8019 horaHrMin_8019 indicativo_0200E horaHrMax_4121  \\\n",
      "0         Varias          12:31            0200E          05:20   \n",
      "1         Varias          12:31            0200E          05:20   \n",
      "2         Varias          12:31            0200E          05:20   \n",
      "3         Varias          12:31            0200E          05:20   \n",
      "4         Varias          12:31            0200E          05:20   \n",
      "\n",
      "  horaHrMin_4121 horaHrMax_8175 horaHrMin_8175  \n",
      "0          16:10         Varias         Varias  \n",
      "1          16:10         Varias         Varias  \n",
      "2          16:10         Varias         Varias  \n",
      "3          16:10         Varias         Varias  \n",
      "4          16:10         Varias         Varias  \n",
      "\n",
      "[5 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "# Identify numeric and non-numeric columns\n",
    "numeric_cols = df_precio.select_dtypes(include=['float64', 'int64']).columns\n",
    "non_numeric_cols = df_precio.select_dtypes(exclude=['float64', 'int64']).columns\n",
    "\n",
    "print(\"Non-numeric columns:\", non_numeric_cols)\n",
    "print(df_precio[non_numeric_cols].head())\n",
    "\n",
    "# Remove all non-numeric columns except 'fecha'\n",
    "columns_to_drop = [col for col in non_numeric_cols if col != 'fecha']\n",
    "df_precio = df_precio.drop(columns_to_drop, axis=1, errors='ignore')\n",
    "df_precio_coor = df_precio.drop(non_numeric_cols, axis=1, errors='ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculamos la correlación con €/kwh\n",
    "correlations = df_precio.corr()['€/kwh'].sort_values(ascending=False)\n",
    "\n",
    "# Mostramos las 10 variables más correlacionadas (excluyendo la propia €/kwh)\n",
    "print(\"Top 10 correlaciones con €/kwh:\")\n",
    "print(correlations[1:11])\n",
    "\n",
    "# Usamos Random Forest para ver la importancia de las características\n",
    "# Seleccionamos solo columnas numéricas\n",
    "numeric_cols = df_precio.select_dtypes(include=['float64', 'int64']).columns\n",
    "X = df_precio[numeric_cols].drop('€/kwh', axis=1)\n",
    "y = df_precio['€/kwh']\n",
    "\n",
    "# Entrenamos un Random Forest\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X, y)\n",
    "\n",
    "# Obtenemos la importancia de las características\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': rf.feature_importances_\n",
    "})\n",
    "\n",
    "# Mostramos las 10 características más importantes según Random Forest\n",
    "print(\"\\nTop 10 características más importantes según Random Forest:\")\n",
    "print(feature_importance.sort_values('importance', ascending=False).head(10))\n",
    "\n",
    "# Visualizamos las 10 características más importantes\n",
    "plt.figure(figsize=(12, 6))\n",
    "top_10_features = feature_importance.sort_values('importance', ascending=False).head(10)\n",
    "plt.bar(top_10_features['feature'], top_10_features['importance'])\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.title('Top 10 características más importantes para predecir €/kwh')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordenar por fecha\n",
    "df_precio = df_precio.sort_values('fecha')\n",
    "\n",
    "# Seleccionar todas las columnas numéricas excepto la variable objetivo\n",
    "X = df_precio_coor.drop('€/kwh', axis=1)\n",
    "y = df_precio['€/kwh']\n",
    "\n",
    "# Escalar los datos\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_seq shape: (57553, 72, 36)\n",
      "y_seq shape: (57553,)\n"
     ]
    }
   ],
   "source": [
    "# Select top 20 most important features\n",
    "# Get temperature, sun and wind related features\n",
    "selected_features = [col for col in X.columns if any(x in col for x in ['tmed', 'sol', 'velmedia'])]\n",
    "X_reduced = X_scaled[:, [list(X.columns).index(feat) for feat in selected_features]]\n",
    "\n",
    "# Create sequences with reduced features\n",
    "def create_sequences(X, y, seq_length=72, batch_size=1000):\n",
    "    n_samples = len(X) - seq_length\n",
    "    X_seq = np.zeros((n_samples, seq_length, X.shape[1]))\n",
    "    y_seq = np.zeros(n_samples)\n",
    "    \n",
    "    for i in range(0, n_samples, batch_size):\n",
    "        end_idx = min(i + batch_size, n_samples)\n",
    "        for j in range(i, end_idx):\n",
    "            X_seq[j] = X[j:j+seq_length]\n",
    "            y_seq[j] = y[j+seq_length]\n",
    "            \n",
    "    return X_seq, y_seq\n",
    "\n",
    "X_seq, y_seq = create_sequences(X_reduced, y.values)\n",
    "\n",
    "# Print the shape of the sequences\n",
    "print(\"X_seq shape:\", X_seq.shape)\n",
    "print(\"y_seq shape:\", y_seq.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tmed_3196',\n",
       " 'velmedia_3196',\n",
       " 'sol_3196',\n",
       " 'tmed_9434',\n",
       " 'velmedia_9434',\n",
       " 'sol_9434',\n",
       " 'tmed_9170',\n",
       " 'velmedia_9170',\n",
       " 'sol_9170',\n",
       " 'tmed_2539',\n",
       " 'velmedia_2539',\n",
       " 'sol_2539',\n",
       " 'tmed_6155A',\n",
       " 'velmedia_6155A',\n",
       " 'sol_6155A',\n",
       " 'tmed_5514',\n",
       " 'sol_5514',\n",
       " 'velmedia_5514',\n",
       " 'tmed_1505',\n",
       " 'velmedia_1505',\n",
       " 'sol_1505',\n",
       " 'tmed_3469A',\n",
       " 'velmedia_3469A',\n",
       " 'sol_3469A',\n",
       " 'tmed_8019',\n",
       " 'velmedia_8019',\n",
       " 'sol_8019',\n",
       " 'tmed_0200E',\n",
       " 'velmedia_0200E',\n",
       " 'sol_0200E',\n",
       " 'tmed_4121',\n",
       " 'velmedia_4121',\n",
       " 'sol_4121',\n",
       " 'tmed_8175',\n",
       " 'velmedia_8175',\n",
       " 'sol_8175']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: optuna in /home/david/proyectos4/p4_venv/lib/python3.10/site-packages (4.2.1)\n",
      "Requirement already satisfied: numpy in /home/david/proyectos4/p4_venv/lib/python3.10/site-packages (from optuna) (2.1.3)\n",
      "Requirement already satisfied: tqdm in /home/david/proyectos4/p4_venv/lib/python3.10/site-packages (from optuna) (4.67.1)\n",
      "Requirement already satisfied: colorlog in /home/david/proyectos4/p4_venv/lib/python3.10/site-packages (from optuna) (6.9.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in /home/david/proyectos4/p4_venv/lib/python3.10/site-packages (from optuna) (2.0.39)\n",
      "Requirement already satisfied: PyYAML in /home/david/proyectos4/p4_venv/lib/python3.10/site-packages (from optuna) (6.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/david/proyectos4/p4_venv/lib/python3.10/site-packages (from optuna) (24.2)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /home/david/proyectos4/p4_venv/lib/python3.10/site-packages (from optuna) (1.15.1)\n",
      "Requirement already satisfied: typing-extensions>=4.12 in /home/david/proyectos4/p4_venv/lib/python3.10/site-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
      "Requirement already satisfied: Mako in /home/david/proyectos4/p4_venv/lib/python3.10/site-packages (from alembic>=1.5.0->optuna) (1.3.9)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/david/proyectos4/p4_venv/lib/python3.10/site-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /home/david/proyectos4/p4_venv/lib/python3.10/site-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 20:41:59,591] A new study created in memory with name: no-name-aa3f668e-9042-47d9-b059-68b47290e3ec\n",
      "2025-03-22 20:42:03.460885: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 149185152 exceeds 10% of free system memory.\n",
      "2025-03-22 20:42:03.692188: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 149185152 exceeds 10% of free system memory.\n",
      "2025-03-22 20:44:18.809821: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 149174784 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout, Input\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Definir función objetivo para Optuna\n",
    "def objective(trial):\n",
    "    # Definir el espacio de búsqueda de hiperparámetros\n",
    "    lstm_units = trial.suggest_int('lstm_units', 20, 64)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    \n",
    "    # Inicializar TimeSeriesSplit\n",
    "    tscv = TimeSeriesSplit(n_splits=3)  # You can adjust the number of splits\n",
    "    \n",
    "    mse_scores = []\n",
    "    \n",
    "    # Loop through each fold in TimeSeriesSplit\n",
    "    for train_idx, val_idx in tscv.split(X_seq):\n",
    "        X_train, X_val = X_seq[train_idx], X_seq[val_idx]\n",
    "        y_train, y_val = y_seq[train_idx], y_seq[val_idx]\n",
    "        \n",
    "        # Definir el modelo LSTM con los hiperparámetros sugeridos\n",
    "        model = Sequential([\n",
    "            Input(shape=(72, len(selected_features))),  # Specify the input shape here\n",
    "            LSTM(lstm_units, activation='relu'),\n",
    "            Dropout(dropout_rate),\n",
    "            Dense(1)\n",
    "        ])\n",
    "        \n",
    "        # Compilar el modelo\n",
    "        model.compile(optimizer='adam', loss='mse')\n",
    "        \n",
    "        # Entrenar el modelo\n",
    "        model.fit(X_train, y_train, epochs=10, batch_size=16, verbose=0)\n",
    "        \n",
    "        # Evaluar el modelo en el conjunto de validación\n",
    "        y_pred = model.predict(X_val)\n",
    "        mse = mean_squared_error(y_val, y_pred)\n",
    "        mse_scores.append(mse)\n",
    "    \n",
    "    # Return the mean MSE across all folds\n",
    "    return np.mean(mse_scores)\n",
    "\n",
    "# Ejecutar la optimización con Optuna\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=10)\n",
    "\n",
    "# Imprimir los mejores hiperparámetros encontrados\n",
    "print(\"Mejores hiperparámetros:\")\n",
    "print(study.best_params)\n",
    "\n",
    "# Imprimir el mejor valor de la función objetivo\n",
    "print(\"Mejor MSE:\")\n",
    "print(study.best_value)\n",
    "\n",
    "# Entrenar el modelo final con los mejores hiperparámetros\n",
    "best_lstm_units = study.best_params['lstm_units']\n",
    "best_dropout_rate = study.best_params['dropout_rate']\n",
    "\n",
    "final_model = Sequential([\n",
    "    LSTM(best_lstm_units, input_shape=(72, len(selected_features)), activation='relu'),\n",
    "    Dropout(best_dropout_rate),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "final_model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Reentrenar con todos los datos\n",
    "final_model.fit(X_seq, y_seq, epochs=10, batch_size=32)\n",
    "\n",
    "# Validación cruzada con series temporales (usando el modelo final)\n",
    "tscv = TimeSeriesSplit(n_splits=3)\n",
    "results = {'LSTM_Optuna': {'mse': [], 'mae': [], 'r2': []}}\n",
    "\n",
    "for train_idx, test_idx in tscv.split(X_seq):\n",
    "    X_train, X_test = X_seq[train_idx], X_seq[test_idx]\n",
    "    y_train, y_test = y_seq[train_idx], y_seq[test_idx]\n",
    "    \n",
    "    # Usar el modelo entrenado con Optuna\n",
    "    y_pred = final_model.predict(X_test)\n",
    "    \n",
    "    # Calcular métricas\n",
    "    results['LSTM_Optuna']['mse'].append(mean_squared_error(y_test, y_pred))\n",
    "    results['LSTM_Optuna']['mae'].append(mean_absolute_error(y_test, y_pred))\n",
    "    results['LSTM_Optuna']['r2'].append(r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar resultados\n",
    "for model_name in results:\n",
    "    print(f\"\\nResultados para {model_name}:\")\n",
    "    print(f\"MSE medio: {np.mean(results[model_name]['mse']):.4f} ± {np.std(results[model_name]['mse']):.4f}\")\n",
    "    print(f\"MAE medio: {np.mean(results[model_name]['mae']):.4f} ± {np.std(results[model_name]['mae']):.4f}\")\n",
    "    print(f\"R2 medio: {np.mean(results[model_name]['r2']):.4f} ± {np.std(results[model_name]['r2']):.4f}\")\n",
    "\n",
    "# Visualizar comparación de modelos\n",
    "plt.figure(figsize=(10, 6))\n",
    "for model_name in results:\n",
    "    plt.plot(results[model_name]['mae'], label=model_name)\n",
    "plt.xlabel('Fold')\n",
    "plt.ylabel('MAE')\n",
    "plt.title('Comparación de MAE por modelo')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p4_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
