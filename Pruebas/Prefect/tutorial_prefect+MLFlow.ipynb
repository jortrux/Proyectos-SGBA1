{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial Prefect + MLFlow\n",
    "Jorge Garrido 4ºINSO Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Que es prefect?\n",
    "\n",
    "Prefect es una herramienta de orquestación de flujos de trabajo y automatización de tareas. Permite a los usuarios definir, ejecutar y monitorear flujos de trabajo complejos de manera eficiente.\n",
    "\n",
    "### Caracteristicas clave:\n",
    "* **Orquestación:** Automatiza la ejecución de tareas en un orden específico.\n",
    "* **Monitorización:** Permite rastrear el estado de las tareas, detectar errores y reiniciar procesos si es necesario.\n",
    "* **Escalabilidad:** Ejecuta tareas localmente o en la nube, facilitando la distribución de cargas de trabajo.\n",
    "\n",
    "### Los decoradores de Prefect:\n",
    "* **@task:** Define una tarea individual que puede ser ejecutada de manera independiente.\n",
    "    * Maneja el registro de logs automáticamente.\n",
    "    * Facilita la reintentos automáticos en caso de errores.\n",
    "    * Se puede ejecutar de forma paralela o distribuida.\n",
    "\n",
    "* **@flow:** Define un flujo de trabajo que puede contener múltiples tareas y especificar su orden de ejecución.\n",
    "    * Administra el orden de ejecución de las tareas.\n",
    "    * Proporciona una vista general del flujo y su estado.\n",
    "    * Permite pasar parámetros entre tareas.\n",
    "* **@parameter:** Define un parámetro que puede ser pasado a una tarea o flujo.\n",
    "\n",
    "\n",
    "## El tutorial:\n",
    "Este tutorial va ha mostrar el uso de los de coradores de task y flow para definir un sencillo flujo de trabajo que entrenara un modelo de IA\n",
    "\n",
    "### Que hace?\n",
    "Al decorar una función con @task, Prefect la convierte en una unidad de trabajo independiente que puede ser monitorizada, reintentada o ejecutada de forma distribuida.\n",
    "\n",
    "Al decorar una función con @flow, Prefect la transforma en un flujo de trabajo que puede contener múltiples tareas y especificar su orden de ejecución."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Decoradores para convertir funciones en tareas y flujos\n",
    "from prefect import flow, task, get_run_logger\n",
    "\n",
    "## manipulacion y generacion de datos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "## entrenar modelos\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "## MLFlow\n",
    "import mlflow\n",
    "import mlflow.sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 1: Cargar y procesar los datos\n",
    "Definimos dos tareas:\n",
    "\n",
    "* cargar_datos: Carga el dataset desde un archivo CSV.\n",
    "* procesar_datos: Separa las características (X) de la variable objetivo (y) y divide los datos en conjuntos de entrenamiento y prueba.\n",
    "\n",
    "\n",
    "get_run_logger() nos permite registrar mensajes en el flujo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@task\n",
    "def cargar_datos(ruta: str) -> pd.DataFrame:\n",
    "    logger = get_run_logger()\n",
    "    logger.info(f\"Cargando datos desde {ruta}\")\n",
    "    datos = pd.read_csv(ruta)\n",
    "    return datos\n",
    "\n",
    "@task\n",
    "def procesar_datos(datos: pd.DataFrame) -> tuple:\n",
    "    logger = get_run_logger()\n",
    "    logger.info(\"Procesando datos\")\n",
    "    X = datos.drop('target', axis=1)\n",
    "    y = datos['target']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 2: Entrenar el modelo\n",
    "Creamos una tarea que entrena un modelo de Random Forest con los datos de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@task\n",
    "def entrenar_modelo(X_train: pd.DataFrame, y_train: pd.Series) -> RandomForestClassifier:\n",
    "    logger = get_run_logger()\n",
    "    logger.info(\"Entrenando modelo RandomForest\")\n",
    "    modelo = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    modelo.fit(X_train, y_train)\n",
    "    return modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 3: Evaluar el modelo\n",
    "Evaluamos el rendimiento del modelo utilizando el conjunto de prueba y calculamos la precisión.\n",
    "\n",
    "* mlflow.log_param(\"n_estimators\", 100): Registra el parámetro n_estimators (número de árboles) del modelo.\n",
    "* mlflow.log_metric(\"accuracy\", precision): Guarda la precisión obtenida en la evaluación del modelo.\n",
    "* mlflow.sklearn.log_model(modelo, \"random_forest_model\"): Guarda el modelo entrenado en el sistema de gestión de modelos de MLflow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@task\n",
    "def evaluar_modelo(modelo: RandomForestClassifier, X_test: pd.DataFrame, y_test: pd.Series) -> float:\n",
    "    logger = get_run_logger()\n",
    "    logger.info(\"Evaluando modelo\")\n",
    "    predicciones = modelo.predict(X_test)\n",
    "    precision = accuracy_score(y_test, predicciones)\n",
    "    logger.info(f\"Precisión del modelo: {precision}\")\n",
    "    \n",
    "    # Registro en MLflow\n",
    "    mlflow.log_param(\"n_estimators\", 100)\n",
    "    mlflow.log_metric(\"accuracy\", precision)\n",
    "    mlflow.sklearn.log_model(modelo, \"random_forest_model\")\n",
    "    \n",
    "    return precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 4: Crear el flujo principal\n",
    "Definimos el flujo principal que conecta todas las tareas definidas anteriormente.\n",
    "\n",
    "* @flow indica que esta función es un flujo de Prefect, que orquesta las tareas.\n",
    "* El flujo ejecuta las tareas en el orden correcto: carga, procesamiento, entrenamiento y evaluación.\n",
    "\n",
    "\n",
    "En el flujo principal, hemos configurado MLflow para que registre cada ejecución del pipeline como un experimento:\n",
    "* mlflow.set_experiment(\"Flujo_ML_Prefect\"): Crea un experimento con el nombre Flujo_ML_Prefect para agrupar las ejecuciones.\n",
    "* mlflow.start_run(): Inicia una nueva ejecución (run) dentro del experimento.\n",
    "\n",
    "\n",
    "### La celda inferior deberia comportarse de la siguiente manera:\n",
    "1. Iniciar del flujo:\n",
    "    * Al llamar flujo_ml(\"datos.csv\"), Prefect inicia el flujo y registra el evento de inicio.\n",
    "\n",
    "2. Ejecuctar la tarea 1 (cargar_datos):\n",
    "    * Prefect ejecuta cargar_datos(ruta_datos).\n",
    "    * Si la tarea se completa con éxito, el flujo pasa automáticamente a la siguiente tarea.\n",
    "    * Si falla, Prefect registra el error y decide reintentar o detenerse, según la configuración.\n",
    "\n",
    "3. Ejecución de la Tarea 2 (procesar_datos):\n",
    "    * Los datos cargados se envían a procesar_datos.\n",
    "    * Prefect monitorea y registra el estado de esta tarea.\n",
    "\n",
    "4. Ejecución de la Tarea 3 (entrenar_modelo):\n",
    "    * El conjunto de entrenamiento es utilizado para entrenar el modelo.\n",
    "    * Prefect registra cuándo comienza y termina el entrenamiento.\n",
    "\n",
    "5. Ejecución de la Tarea 4 (evaluar_modelo):\n",
    "    * El modelo entrenado es evaluado con el conjunto de prueba.\n",
    "    * La precisión calculada se registra en los logs de prefect.\n",
    "\n",
    "6. Finalización del Flujo:\n",
    "    * Una vez que todas las tareas se completan, prefect marca el flujo como Success y registra la precisión final en los logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">19:53:09.815 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | prefect - Starting temporary server on <span style=\"color: #0000ff; text-decoration-color: #0000ff\">http://127.0.0.1:8830</span>\n",
       "See <span style=\"color: #0000ff; text-decoration-color: #0000ff\">https://docs.prefect.io/3.0/manage/self-host#self-host-a-prefect-server</span> for more information on running a dedicated Prefect server.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "19:53:09.815 | \u001b[36mINFO\u001b[0m    | prefect - Starting temporary server on \u001b[94mhttp://127.0.0.1:8830\u001b[0m\n",
       "See \u001b[94mhttps://docs.prefect.io/3.0/manage/self-host#self-host-a-prefect-server\u001b[0m for more information on running a dedicated Prefect server.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">19:53:19.815 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'vegan-anteater'</span> - Beginning flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'vegan-anteater'</span> for flow<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> 'flujo-ml'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "19:53:19.815 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'vegan-anteater'\u001b[0m - Beginning flow run\u001b[35m 'vegan-anteater'\u001b[0m for flow\u001b[1;35m 'flujo-ml'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/02/11 19:53:19 INFO mlflow.tracking.fluent: Experiment with name 'Flujo_ML_Prefect' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">19:53:21.262 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'cargar_datos-945' - Cargando datos desde datos.csv\n",
       "</pre>\n"
      ],
      "text/plain": [
       "19:53:21.262 | \u001b[36mINFO\u001b[0m    | Task run 'cargar_datos-945' - Cargando datos desde datos.csv\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">19:53:21.309 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'cargar_datos-945' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "19:53:21.309 | \u001b[36mINFO\u001b[0m    | Task run 'cargar_datos-945' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">19:53:21.631 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'procesar_datos-a1d' - Procesando datos\n",
       "</pre>\n"
      ],
      "text/plain": [
       "19:53:21.631 | \u001b[36mINFO\u001b[0m    | Task run 'procesar_datos-a1d' - Procesando datos\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">19:53:21.647 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'procesar_datos-a1d' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "19:53:21.647 | \u001b[36mINFO\u001b[0m    | Task run 'procesar_datos-a1d' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">19:53:21.900 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'entrenar_modelo-e59' - Entrenando modelo RandomForest\n",
       "</pre>\n"
      ],
      "text/plain": [
       "19:53:21.900 | \u001b[36mINFO\u001b[0m    | Task run 'entrenar_modelo-e59' - Entrenando modelo RandomForest\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">19:53:22.045 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'entrenar_modelo-e59' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "19:53:22.045 | \u001b[36mINFO\u001b[0m    | Task run 'entrenar_modelo-e59' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">19:53:22.295 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'evaluar_modelo-2aa' - Evaluando modelo\n",
       "</pre>\n"
      ],
      "text/plain": [
       "19:53:22.295 | \u001b[36mINFO\u001b[0m    | Task run 'evaluar_modelo-2aa' - Evaluando modelo\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">19:53:22.317 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'evaluar_modelo-2aa' - Precisión del modelo: 0.5\n",
       "</pre>\n"
      ],
      "text/plain": [
       "19:53:22.317 | \u001b[36mINFO\u001b[0m    | Task run 'evaluar_modelo-2aa' - Precisión del modelo: 0.5\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/02/11 19:53:30 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">19:53:30.327 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'evaluar_modelo-2aa' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "19:53:30.327 | \u001b[36mINFO\u001b[0m    | Task run 'evaluar_modelo-2aa' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión final del modelo: 0.5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">19:53:30.383 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'vegan-anteater'</span> - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "19:53:30.383 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'vegan-anteater'\u001b[0m - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@flow\n",
    "def flujo_ml(ruta_datos: str):\n",
    "    mlflow.set_experiment(\"Flujo_ML_Prefect\")\n",
    "    with mlflow.start_run():\n",
    "        datos = cargar_datos(ruta_datos)\n",
    "        X_train, X_test, y_train, y_test = procesar_datos(datos)\n",
    "        modelo = entrenar_modelo(X_train, y_train)\n",
    "        precision = evaluar_modelo(modelo, X_test, y_test)\n",
    "        print(f\"Precisión final del modelo: {precision}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    flujo_ml(\"datos.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizar MLFLOW:\n",
    "Para visualizar los experimentos y resultados, abre la interfaz web de MLflow ejecutando el siguiente comando en la terminal:  \n",
    "Esto abrira una interfaz con la ui del mlflow en la direccion http://localhost:5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!mlflow ui"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
