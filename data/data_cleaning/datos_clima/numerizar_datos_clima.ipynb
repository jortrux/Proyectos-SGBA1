{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directorio de trabajo actual: /\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "ruta_base = '../../'\n",
    "\n",
    "# Cambiar el directorio de trabajo\n",
    "os.chdir(ruta_base)\n",
    "\n",
    "print(\"Directorio de trabajo actual:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_clima_ejemplo = pd.read_csv('processed/datos_clima/0200E_clima_completo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tipos de datos de las columnas\n",
    "print(df_clima_ejemplo.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numerizar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_procesado = df_clima_ejemplo.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Procesar fechas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Procesamiento de fechas y horas\n",
    "# Convertir fecha a datetime y extraer características\n",
    "df_procesado['fecha'] = pd.to_datetime(df_procesado['fecha'])\n",
    "df_procesado['año'] = df_procesado['fecha'].dt.year\n",
    "df_procesado['mes'] = df_procesado['fecha'].dt.month\n",
    "df_procesado['dia'] = df_procesado['fecha'].dt.day\n",
    "df_procesado['dia_semana'] = df_procesado['fecha'].dt.dayofweek\n",
    "df_procesado['estacion_año'] = df_procesado['fecha'].dt.month % 12 // 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Procesar columnas de Horas y minutos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_procesado.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_procesado['horaPresMax'].unique())\n",
    "print(df_procesado['horaPresMin'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_procesado['horaracha'].unique())\n",
    "print(df_procesado['horatmax'].unique())\n",
    "print(df_procesado['horatmin'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['horatmin', 'horatmax', 'horaracha', ]:\n",
    "    if col in df_procesado.columns:\n",
    "        # Ensure the column is of string type before applying the ~ operator\n",
    "        df_procesado[col] = df_procesado[col].astype(str)\n",
    "        print(col)\n",
    "        print(df_procesado[col][~df_procesado[col].str.contains(':')].unique())\n",
    "    else:\n",
    "        print(f\"La columna '{col}' no existe en el DataFrame.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertir_hora_a_minutos(x):\n",
    "    if pd.isna(x) or x == 'nan':\n",
    "        return pd.NA\n",
    "    \n",
    "    if x == 'Varias':\n",
    "        # -1 podría ser un marcador para 'Varias'\n",
    "        # (lo normalizaremos después, así que el -1 no afectará al modelo)\n",
    "        return -1\n",
    "        \n",
    "    # Solo proceder si tiene el formato HH:MM esperado\n",
    "    if isinstance(x, str) and ':' in x and x.replace(':', '').isdigit():\n",
    "        try:\n",
    "            horas, minutos = x.split(':')\n",
    "            return int(horas) * 60 + int(minutos)\n",
    "        except (ValueError, TypeError):\n",
    "            return pd.NA\n",
    "    else:\n",
    "        return pd.NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir horas a valores numéricos con codificación especial\n",
    "max_minutes = 24 * 60  # Total minutos en un día\n",
    "\n",
    "for col in ['horatmin', 'horatmax', 'horaracha']:\n",
    "    if col in df_procesado.columns:\n",
    "        # Crear columna para indicar si es 'Varias'\n",
    "        df_procesado[f'{col}_varias'] = (df_procesado[col] == 'Varias').astype(int)\n",
    "        df_procesado[f'{col}_minutos'] = df_procesado[col].apply(convertir_hora_a_minutos)\n",
    "        \n",
    "        # Paso adicional: Normalizar entre 0 y 2pi para representación cíclica del tiempo\n",
    "        # Filtrar solo los valores válidos (que no son NaN o -1)\n",
    "        valid_mask = df_procesado[f'{col}_minutos'].notna() & (df_procesado[f'{col}_minutos'] != -1)\n",
    "        valid_minutes = df_procesado.loc[valid_mask, f'{col}_minutos']\n",
    "        \n",
    "        # Crear las columnas seno y coseno para capturar la naturaleza cíclica del tiempo\n",
    "        df_procesado[f'{col}_sin'] = np.nan\n",
    "        df_procesado[f'{col}_cos'] = np.nan\n",
    "        \n",
    "        # Asignar los valores trigonométricos solo para los valores válidos\n",
    "        if not valid_minutes.empty:\n",
    "            # Convertir minutos a ángulos (0 a 2π)\n",
    "            angles = valid_minutes.astype(float) * (2 * np.pi / max_minutes)\n",
    "            df_procesado.loc[valid_mask, f'{col}_sin'] = np.sin(angles)\n",
    "            df_procesado.loc[valid_mask, f'{col}_cos'] = np.cos(angles)\n",
    "\n",
    "# Comprobar que las columnas se han creado correctamente\n",
    "print(\"Columnas para horatmin:\")\n",
    "print(df_procesado[['horatmin_varias', 'horatmin_sin', 'horatmin_cos']].head())\n",
    "print(\"\\nColumnas para horatmax:\")\n",
    "print(df_procesado[['horatmax_varias', 'horatmax_sin', 'horatmax_cos']].head())\n",
    "print(\"\\nColumnas para horaracha:\")\n",
    "print(df_procesado[['horaracha_varias', 'horaracha_sin', 'horaracha_cos']].head())\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Procesar columnas de solo Horas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertir_hora_entera(x):\n",
    "    if pd.isna(x) or x == 'nan':\n",
    "        return pd.NA\n",
    "    \n",
    "    if x == 'Varias':\n",
    "        return -1\n",
    "    \n",
    "    try:\n",
    "        # Convertir a entero (estas columnas solo tienen horas enteras)\n",
    "        hora = int(x)\n",
    "    \n",
    "        # Manejar el caso especial de '24' (debería ser '00')\n",
    "        if hora == 24:\n",
    "            hora = 0\n",
    "            \n",
    "        # Convertir a minutos para mantener consistencia con otras columnas\n",
    "        return hora * 60\n",
    "    except (ValueError, TypeError):\n",
    "        return pd.NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir horas de presión a valores numéricos (formato específico)\n",
    "for col in ['horaPresMax', 'horaPresMin']:\n",
    "    if col in df_procesado.columns:\n",
    "        # Crear columna para indicar si es 'Varias'\n",
    "        df_procesado[f'{col}_varias'] = (df_procesado[col] == 'Varias').astype(int)\n",
    "        df_procesado[f'{col}_minutos'] = df_procesado[col].apply(convertir_hora_entera)\n",
    "\n",
    "        # Normalización circular (valores entre 0 y 2π)\n",
    "        valid_minutes = df_procesado[df_procesado[f'{col}_minutos'] >= 0][f'{col}_minutos']\n",
    "        if not valid_minutes.empty:\n",
    "            max_minutes = 24 * 60  # 24 horas * 60 minutos\n",
    "            \n",
    "            # Convertir a valores circulares\n",
    "            df_procesado[f'{col}_sin'] = np.where(\n",
    "                df_procesado[f'{col}_minutos'] >= 0,\n",
    "                np.sin(2 * np.pi * df_procesado[f'{col}_minutos'] / max_minutes),\n",
    "                0  # Valor por defecto para NA o 'Varias'\n",
    "            )\n",
    "            \n",
    "            df_procesado[f'{col}_cos'] = np.where(\n",
    "                df_procesado[f'{col}_minutos'] >= 0,\n",
    "                np.cos(2 * np.pi * df_procesado[f'{col}_minutos'] / max_minutes),\n",
    "                0  # Valor por defecto para NA o 'Varias'\n",
    "            )\n",
    "        \n",
    "        # Eliminar la columna original y la intermedia\n",
    "        df_procesado = df_procesado.drop(columns=[col, f'{col}_minutos'])\n",
    "\n",
    "# Comprobar que las columnas se han creado correctamente\n",
    "print(\"Columnas para horaPresMax:\")\n",
    "print(df_procesado[['horaPresMax_varias', 'horaPresMax_sin', 'horaPresMax_cos']].tail())\n",
    "print(\"\\nColumnas para horaPresMin:\")\n",
    "print(df_procesado[['horaPresMin_varias', 'horaPresMin_sin', 'horaPresMin_cos']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Procesar precipitación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valores únicos en la columna 'precipitacion'\n",
    "print(df_procesado['prec'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertir_precipitacion(x):\n",
    "        if pd.isna(x):\n",
    "            return np.nan\n",
    "        \n",
    "        if isinstance(x, (int, float)):\n",
    "            return float(x)\n",
    "        \n",
    "        if isinstance(x, str) and x == 'Ip':\n",
    "            # Valor inapreciable: asignamos un valor pequeño (0.05 mm)\n",
    "            return 0.05\n",
    "            \n",
    "        # Por si hay algún otro string inesperado\n",
    "        try:\n",
    "            return float(x)\n",
    "        except (ValueError, TypeError):\n",
    "            return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procesamiento simplificado de la columna de precipitación\n",
    "if 'prec' in df_procesado.columns:\n",
    "    # Crear columna indicadora para precipitación inapreciable\n",
    "    df_procesado['prec_inapreciable'] = df_procesado['prec'].apply(\n",
    "        lambda x: 1 if isinstance(x, str) and x == 'Ip' else 0)\n",
    "       \n",
    "    # Aplicar la conversión\n",
    "    df_procesado['prec_valor'] = df_procesado['prec'].apply(convertir_precipitacion)\n",
    "    \n",
    "    # Transformación logarítmica para manejar la naturaleza sesgada de las precipitaciones\n",
    "    # Agregamos 1 para evitar log(0) y usar log(1+x)\n",
    "    df_procesado['prec_log'] = np.log1p(df_procesado['prec_valor'])\n",
    "    \n",
    "    # Eliminamos la columna original\n",
    "    df_procesado = df_procesado.drop(columns=['prec'])\n",
    "\n",
    "# Comprobar que las columnas se han creado correctamente\n",
    "print(\"Columnas para precipitación:\")\n",
    "print(df_procesado[['prec_inapreciable', 'prec_valor', 'prec_log']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Asegurar que las columnas float lo son"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asegurar que las columnas que deben ser de tipo float lo sean\n",
    "# altitud, tmed, tmin, tmax, dir, velmedia, sol, presmax, presmin, hrmedia\n",
    "\n",
    "# Verificar qué columnas existen en el dataframe\n",
    "available_cols = []\n",
    "for col in ['altitud', 'tmed', 'tmin', 'tmax', 'dir', 'velmedia', 'racha', 'sol', 'presMax', 'presMin', 'hrMedia']:\n",
    "\tif col in df_procesado.columns:\n",
    "\t\tavailable_cols.append(col)\n",
    "\n",
    "# Convertir columnas a float si existen en el dataframe\n",
    "for col in available_cols:\n",
    "\ttry:\n",
    "\t\tdf_procesado[col] = df_procesado[col].astype(float)\n",
    "\texcept ValueError:\n",
    "\t\t# Si hay valores que no se pueden convertir (como comas en lugar de puntos)\n",
    "\t\tif isinstance(df_procesado[col][0], str) and ',' in df_procesado[col][0]:\n",
    "\t\t\tdf_procesado[col] = df_procesado[col].str.replace(',', '.').astype(float)\n",
    "\t\telse:\n",
    "\t\t\tprint(f\"No se pudo convertir la columna {col} a tipo float.\")\n",
    "\n",
    "# Comprobar que las columnas se han convertido correctamente\n",
    "print(df_procesado[available_cols].dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verificación de tipos de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_procesado.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_procesado['racha'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar columnas que no se usarán en el modelo\n",
    "\n",
    "# nombre                        object\n",
    "# provincia                     object\n",
    "# horatmin                      object\n",
    "# horatmax                      object\n",
    "# horaracha                     object\n",
    "\n",
    "columnas_eliminar = ['nombre', 'provincia', 'horatmin', 'horatmax', 'horaracha']\n",
    "df_procesado = df_procesado.drop(columns=columnas_eliminar)\n",
    "\n",
    "print(df_procesado.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardar el dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el dataframe procesado\n",
    "ruta = 'data/processed/datos_clima/0200E_clima_Numerizado'\n",
    "# df_procesado.to_parquet(ruta+\".parquet\", index=False)\n",
    "df_procesado.to_csv(ruta+\".parquet\", index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p4_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
